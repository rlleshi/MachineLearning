{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting human wine test preference, Part 3\n",
    "\n",
    "## XGBoost\n",
    "\n",
    "The method that we used in the last notebook was boostrap agreggating (bagging). In this method we have 2 randomizing processes which ensure the uniqueness of the tree:\n",
    "\n",
    "1. Pick a random number of features from the feature vector\n",
    "2. Pick a random number of samples\n",
    "\n",
    "We now turn our attention to XGBoost which is state-of-the-art in the world of Decision Trees. XGBoost uses a method known as gradient boosting. In the standard ensemble model, all models were trained in isolation and so they ended up doing the same mistakes.\n",
    "\n",
    "XGBoost, however solves this by training the trees in succession each time improving on the mistakes of the previous model. Models are trained subsequently and each subsequent train aims to improve the errors made by the previous one.\n",
    "\n",
    "Among the advantages of XGBoost one can mention\n",
    "\n",
    "- Has default regularization (regularized boosting)\n",
    "- Implements parallel processing that make it blazingly fast (also supports Hadoop implementation)\n",
    "- High flexibility: It allows the users to define custom optimization objectives and evaluation criteria\n",
    "- Has build-in routine to handle missing values\n",
    "- Splits upto max_depth and then prunes the tree backwards\n",
    "- Build-in Cross-Validation\n",
    "- Continue where left of\n",
    "    - Users can start training the XGBoost model from the last iteration of the previous run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset consists of 4898 samples and 11 features\n"
     ]
    }
   ],
   "source": [
    "features = pd.read_csv('data\\winequality.csv')\n",
    "labels = features['quality']\n",
    "features.drop('quality', inplace=True, axis=1)\n",
    "print('The dataset consists of {} samples and {} features'.format(*features.shape))\n",
    "\n",
    "# Train/Test\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.2,\n",
    "                                                                           random_state=1, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(predictions, test_labels):\n",
    "    \"\"\" Model evaluation tolerating a prediction of difference 1.\n",
    "        That is if we predicted 3 or 5 but the real value was 4, we still count it as correct.\"\"\"\n",
    "    confusion_mat = confusion_matrix(test_labels, predictions)\n",
    "    \n",
    "    # Calculate tolerance micro precision\n",
    "    sumTp = 0\n",
    "    sumTpFp = sum(sum(confusion_mat))\n",
    "\n",
    "    for i in range(len(confusion_mat)):\n",
    "        for j in range(len(confusion_mat)):\n",
    "            # element in main diagonal\n",
    "            if (i == j):\n",
    "                sumTp += confusion_mat[i][j]\n",
    "\n",
    "            # element around main diagonal\n",
    "            elif (j == i+1) & (i<5):\n",
    "                sumTp += confusion_mat[i][j]\n",
    "\n",
    "            elif (j == i-1) & (i>0):\n",
    "                sumTp += confusion_mat[i][j]\n",
    "                \n",
    "    microP = sumTp/sumTpFp\n",
    "    print(\"Tolerance precision:\", round(100*microP, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost can be used in two versions. First is the original version, second a wrapper provided for sklearn.\n",
    "\n",
    "We first investiage the original version and initialize it with some kind of random values for the hyperparameters.\n",
    "\n",
    "[Docs](https://xgboost.readthedocs.io/en/latest/parameter.html) on hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tolerance precision: 96.22\n"
     ]
    }
   ],
   "source": [
    "# Convert into suitable data format for XGBoost\n",
    "train = xgb.DMatrix(train_features, train_labels)\n",
    "test = xgb.DMatrix(test_features, test_labels)\n",
    "\n",
    "param = {\n",
    "    'max_depth': 5,\n",
    "    'eta': 0.3,\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 10,\n",
    "    'gamma':0,\n",
    "    'min_child_weight':1} \n",
    "\n",
    "steps = 10\n",
    "\n",
    "# Train the model\n",
    "model1 = xgb.train(param, train, steps)\n",
    "\n",
    "# Test\n",
    "predictions = model1.predict(test)\n",
    "evaluate_model(predictions, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An accuracy of 96.22% is not bad for a starter. Let us see if we can improve it using hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparemeter tunning\n",
    "\n",
    "To do hyperparameter tuning we shall use the wrapper for sklearn\n",
    "\n",
    "[Docs](https://xgboost.readthedocs.io/en/latest/python/python_api.html) on hyperparameters of the wrapped version\n",
    "\n",
    "The parameters are divided into three categories. Some of the main parameters are listed below\n",
    "\n",
    "1. General Parameters: Overal functioning\n",
    "    - booster: Type of model to run at each iteration. Tree-based or linear model\n",
    "    - num_feature: #of features in the feature vector that are actually used in boosting. Max by default\n",
    "2. Booster Parameters. Tree considered here (but it also almost always outperforms the linear booster): Individual booster at each step\n",
    "    - eta: the learning rate. Makes the model robust by shrinking the weights in each step. Dampens the decision power of the individual trees.\n",
    "    - min_child_weight: Min sum of weights of all observations required in a child. Controls overfitting. Too higher values, however could also lead to underfit\n",
    "    - max_depth: The maximal depth of the tree. Controls overfitting\n",
    "    - max_leaf_nodes: The maximal number of nodes in the leafes. Alternative to max_depth\n",
    "    - gamma: minimal loss reduction required to make the split\n",
    "    - lambda: L2 regularization term on weights(Ridge). Increasing the value makes the model more conservative\n",
    "    - alpha: L1 regularization term(Lasso). Likewise makes the model more convervative.\n",
    "    - scale_pos_weight: A value greater than 0 helps in a faster convergance for imbalanced classes. 1 by default.\n",
    "3. Learning Task Parameters: Optimization performed\n",
    "    - objective: The lost function to be minimized\n",
    "        - *binary:logistic*  For a bernoulli distribution. Returns probabilities\n",
    "        - *multi:softmax*  For a multinomial distirbution using softmax. Returns predicted class. Also need to set the *num_class* which defines the number of unique classes\n",
    "        - *multi:soft* Same as softmax but it returns probabilities\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we try out random parameters out of a pool of huge number of parameters using **RandomSearchCV**. Then we shall narrow down the search using **GridSearchCV**.\n",
    "\n",
    "The time taken to try out all can grow quite a lot because we are training an ensemble of decision trees many times over. Here we do 500 iterations totaling 1500 fits of CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 500 candidates, totalling 1500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   14.9s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 11.8min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed: 16.7min\n",
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed: 23.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1144 tasks      | elapsed: 30.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed: 39.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1500 out of 1500 | elapsed: 40.7min finished\n"
     ]
    }
   ],
   "source": [
    "model2 = xgb.XGBClassifier(objective='multi:softmax', booster='gbtree', random_state=1)\n",
    "parameters = {\n",
    "    'max_depth': [i for i in range(2,13)],\n",
    "    'min_child_weight': [i for i in range(1,10)],\n",
    "    'learning_rate': [i for i in np.linspace(0.1,0.3, 8)],\n",
    "    'gamma': [i for i in np.linspace(0.1, 1.5, 4)],\n",
    "    'reg_lambda ':[0,1],\n",
    "    'scale_pos_weight':[1],\n",
    "    'num_clas':[10],\n",
    "    'tree_method': ['auto', 'exact', 'approx', 'gpu_hist']\n",
    "}\n",
    "\n",
    "randomSearch = RandomizedSearchCV(estimator=model2, param_distributions=parameters, \n",
    "                          scoring='neg_mean_absolute_error',\n",
    "                          cv=3, verbose=5, n_jobs=-1, n_iter=500)\n",
    "\n",
    "randomSearch.fit(train_features, train_labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters that we tried out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
       " 'min_child_weight': [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " 'learning_rate': [0.1,\n",
       "  0.1285714285714286,\n",
       "  0.15714285714285714,\n",
       "  0.18571428571428572,\n",
       "  0.2142857142857143,\n",
       "  0.24285714285714285,\n",
       "  0.27142857142857146,\n",
       "  0.3],\n",
       " 'gamma': [0.1, 0.5666666666666667, 1.0333333333333332, 1.5],\n",
       " 'reg_alpha ': [0, 1],\n",
       " 'scale_pos_weight': [1],\n",
       " 'num_clas': [10],\n",
       " 'tree_method': ['auto', 'exact', 'approx', 'gpu_hist']}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best random parameters that the algorithm was able to find for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tree_method': 'approx',\n",
       " 'scale_pos_weight': 1,\n",
       " 'reg_lambda ': 1,\n",
       " 'num_clas': 10,\n",
       " 'min_child_weight': 6,\n",
       " 'max_depth': 12,\n",
       " 'learning_rate': 0.3,\n",
       " 'gamma': 0.5666666666666667}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomSearch.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tolerance precision: 96.12\n"
     ]
    }
   ],
   "source": [
    "best_model = randomSearch.best_estimator_\n",
    "predictions2 = best_model.predict(test_features)\n",
    "evaluate_model(predictions2, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance slightly decreased.\n",
    "\n",
    "Now let's narrow down the search using **GridSearch**. We try 960 candidates for an unreasonable amount of time (in such cases apache spark might be of benefit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 960 candidates, totalling 2880 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   43.6s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed: 13.0min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 20.3min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed: 29.0min\n",
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed: 40.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1144 tasks      | elapsed: 52.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed: 66.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed: 82.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2170 tasks      | elapsed: 99.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2584 tasks      | elapsed: 119.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2880 out of 2880 | elapsed: 133.4min finished\n"
     ]
    }
   ],
   "source": [
    "model3 = xgb.XGBClassifier(objective='multi:softmax', booster='gbtree', random_state=1)\n",
    "grid_params = {\n",
    "    'max_depth': [i for i in range(10,15)],\n",
    "    'min_child_weight': [i for i in range(5,8)],\n",
    "    'learning_rate': [i for i in np.linspace(0.2,0.5, 4)],\n",
    "    'gamma': [i for i in np.linspace(0.5, 0.7, 4)],\n",
    "    'reg_lambda':[0.2, 0.5, 0.7, 1],\n",
    "    'scale_pos_weight':[1],\n",
    "    'num_clas':[10],\n",
    "    'tree_method': ['approx']\n",
    "}\n",
    "gridSearch = GridSearchCV(estimator=model3, param_grid=grid_params, cv=3, n_jobs=-1, verbose=5, \n",
    "                          scoring='neg_mean_absolute_error')\n",
    "\n",
    "gridSearch.fit(train_features, train_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tolerance precision: 96.63\n"
     ]
    }
   ],
   "source": [
    "best_model2 = gridSearch.best_estimator_\n",
    "predictions3 = best_model2.predict(test_features)\n",
    "evaluate_model(predictions3, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Although we managed to slightly increase the performance, this model does not perform better that the bagging implementation of Random Forests by sklearn as seen in notebook #2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
